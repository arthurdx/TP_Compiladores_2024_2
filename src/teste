import string
from utils import token_map

def read_java_file(filename):
    with open(filename, 'r') as file:
        output = []
        current_line = 0
        reading_comment = False
        for line in file:
            current_row = 0
            current_word = ""

            if not reading_comment:
                while current_row < len(line):
                    ch = line[current_row]
                    if ch == '/' and current_row + 1 < len(line) and line[current_row + 1] == '/':
                        break

                    elif ch == '/' and current_row + 1 < len(line) and line[current_row + 1] == '*':
                        comment_start_line = current_line
                        reading_comment = True
                        current_row += 1
                        break

                    if ch.isalpha():
                        current_word += ch
                    elif ch.isdigit() or (ch == '.' and current_word and current_word[-1].isdigit()):
                        current_word += ch
                    elif ch == 'x' and current_word == '0':  # Detecta hexadecimal
                        current_word += ch
                    elif ch == '"':  # Verifica strings
                        if current_word:
                            process_token(current_word, output, current_line, current_row)
                            current_word = ""
                        current_word += ch
                        current_row += 1
                        while current_row < len(line) and line[current_row] != '"':
                            current_word += line[current_row]
                            current_row += 1
                        if current_row < len(line):
                            current_word += '"'
                            process_token(current_word, output, current_line, current_row)
                            current_word = ""
                        else:
                            assert False, f'String não fechada na linha {current_line + 1}: {current_word}'

                    # Verifica símbolos
                    elif ch in string.punctuation:
                        if current_word:
                            process_token(current_word, output, current_line, current_row)
                            current_word = ""
                        symbol_token = identify_symbol(line, current_row, current_line)
                        assert symbol_token is not None, f"Símbolo inválido na linha {current_line + 1}: '{ch}'"
                        process_token(symbol_token, output, current_line, current_row)
                        current_row += len(symbol_token) - 1

                    else:
                        if current_word:
                            process_token(current_word, output, current_line, current_row)
                            current_word = ""

                    current_row += 1

                current_line += 1
                if current_word:
                    process_token(current_word, output, current_line, current_row)
            else:
                current_line += 1
                while '*/' not in line:
                    current_line += 1
                    assert len(line) > 1, f'Bloco de comentário não fechado, linha: {comment_start_line + 1}'
                    line = next(file, '')
                reading_comment = False

        return output

def process_token(word, output, current_line, current_row):
    try:
        token = identify_number(word) if word not in token_map else list(token_map[word].values())[0]

        if token:
            output_line = (token, word, current_line, current_row - len(word))
            output.append(output_line)
        else:
            assert False, f"Token desconhecido na linha {current_line + 1}: '{word}'"
    except Exception as e:
        print(f"Erro ao processar token: {e}")
